{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMO8M/5t2VGPD8hKZWWfLr7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":20,"metadata":{"id":"LrKBWzlCPA8Q","executionInfo":{"status":"error","timestamp":1678808018950,"user_tz":-330,"elapsed":6046,"user":{"displayName":"CE138_Meet_Sukhadiya","userId":"17999769234007530522"}},"colab":{"base_uri":"https://localhost:8080/","height":665},"outputId":"8640e0ee-5e5a-4b19-95e9-58e23741d0fd"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([100, 784])\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","name":"stderr","text":["<ipython-input-20-d38a39542c3c>:108: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n","  sample = torch.tensor(sample)\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-d38a39542c3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-20-d38a39542c3c>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0mlebel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mlebel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-20-d38a39542c3c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (28x28 and 784x100)"]}],"source":["import matplotlib.pyplot as plt\n","import math\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader\n","import tensorflow\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.datasets import mnist\n","from sklearn.preprocessing import MinMaxScaler\n","from random import random\n","# from sklearn.preprocessing import transform\n","class ANNModel(nn.Module):\n","\n","  def __init__(self, input_dim, hidden_dim, output_dim):\n","    super(ANNModel, self).__init__()\n","    self.a1 = nn.Linear(input_dim, hidden_dim)\n","    self.sig = nn.Sigmoid()\n","    self.a2 = nn.Linear(hidden_dim, output_dim)\n","\n","  def forward(self, x):\n","      out = self.a1(x)\n","      out = self.sig(out)\n","      out = self.a2(out)\n","      out = self.sig(out)\n","      return out\n","  def predict(self, x):\n","      output = self.forward(x).tolist()[0]\n","      lebel = output.index(max(output))\n","      return lebel\n","\n","(X_train, y_train), (X_test, y_test) = mnist.load_data()\n","x_train = X_train[0:100]\n","Y_train = y_train[0:100]\n","l_data =[]\n","\n","\n","# 1D array\n","\n","len1 = len(x_train)\n","for _ in range(len1):\n","  samples = x_train[_]\n","  len2 = len(samples)\n","  xi=[]\n","  for i in range(len2):\n","    for j in range(len2):\n","      xi.append(samples[i][j])\n","  l_data.append(list(np.array(xi, dtype='float32')))\n","\n","# normalise\n","\n","l_data = np.array(l_data)\n","sc = MinMaxScaler().fit(l_data)\n","X_t = sc.transform(l_data)\n","\n","# Converting to tensorsn training\n","\n","x_train = torch.tensor(l_data)\n","Y_train = torch.tensor(Y_train)\n","\n","# Converting to tensors test\n","\n","X_test = torch.tensor(X_test)\n","y_test = torch.tensor(y_test)\n","\n","batch_s = 10\n","n_itr = 5000\n","n_ep = n_itr/(len(x_train) / batch_s)\n","n_ep = int(n_ep)\n","\n","input_dim = x_train.shape[1]\n","hidden_dim = 100\n","output_dim = 10\n","\n","model = ANNModel(input_dim, hidden_dim, output_dim)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","learning_rate = 0.02\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n","\n","tensords = torch.utils.data.TensorDataset(x_train, Y_train)\n","print(x_train.shape)\n","\n","dataloader =  torch.utils.data.DataLoader(tensords, batch_size=batch_s,shuffle=True)\n","\n","for epoch in range(n_ep):\n","  for i, (x,y) in enumerate(dataloader):\n","    x = Variable(x.view(-1, input_dim))\n","    y = Variable(y)\n","    output = model(x)\n","    optimizer.zero_grad()\n","    loss = criterion(output,y)\n","    loss.backward()\n","    optimizer.step() \n","  \n","# random image\n","\n","im=X_train[int(random()*len(X_train))]\n","plt.imshow(im)\n","plt.show()\n","xj=[]\n","sample=[]\n","for k in im:\n","  for x in k:\n","    \n","\n","print(model.predict(sample))"]}]}